{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ğŸ“„ Image Classification ëŒ€íšŒ**\n",
    "> ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒ\n",
    "> EfficientNet ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬, ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì¼ ìƒì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤\n",
    "\n",
    "## Contents\n",
    "- Imort Library & Define Functions\n",
    "- Hyper-tuning\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inderence & save File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œ\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from timm.data.mixup import Mixup\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê²°ê³¼ì˜ ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic=True \n",
    "torch.backends.cudnn.benchmark=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ëª¨ë‹ˆí„°ë§ (wandb ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgimjeongheon38\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "!wandb login\n",
    "\n",
    "#entitiy : ê³ ì • , project : 'ë³¸ì¸ì´ë¦„_cv' ì´ëŸ° ëŠë‚Œ, name : \"ì²«ë²ˆì¨° ì‹œë„\" ... etc  \n",
    "run = wandb.init(project=\"kimjeongheon_cv\", entity = 'CV_ëŒ€íšŒ', name ='TopOfTheWorld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyper-parameters\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model config\n",
    "model_name = 'efficientnet_b4'\n",
    "\n",
    "# training config\n",
    "img_size = 380\n",
    "LR = 0.001717\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "num_workers = 8\n",
    "\n",
    "#focal loss\n",
    "loss_alpha = 0.55\n",
    "loss_gamma = 1.477\n",
    "\n",
    "#AdamW - optimizer\n",
    "dropout_ratio = 0.3 \n",
    "\n",
    "# ì¦ê°• ë°ì´í„° ë°°ìˆ˜ ì„¤ì •\n",
    "num_augmentations = 10\n",
    "#aug\n",
    "alpha = 0.621\n",
    "mixup_prob =  0.3853\n",
    "\n",
    "use_amp=True\n",
    "\n",
    "#gradient\n",
    "accumulation_steps = 2\n",
    "\n",
    "\n",
    "wandb.config.update({\n",
    "    \"model_name\": model_name,\n",
    "    \"img_size\": img_size,\n",
    "    \"LR\" : LR,\n",
    "    \"BATCH_SIZE\":BATCH_SIZE,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"loss_alpha\" : loss_alpha,\n",
    "    \"loss_gamma\" : loss_gamma,\n",
    "    \"dropout_ratio\" : dropout_ratio,\n",
    "    \"num_augmentations\": num_augmentations,\n",
    "    \"alpha\": alpha,\n",
    "    \"mixup_prob\":mixup_prob\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, val_loader=None, epoch=None, mixup_fn=None, accumulation_steps=2, use_amp=True):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    scaler = GradScaler(enabled=use_amp)  # GradScaler ì´ˆê¸°í™”\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "\n",
    "    for i, (image, targets) in enumerate(pbar):\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        if mixup_fn is not None:\n",
    "            image, targets = mixup_fn(image, targets)\n",
    "\n",
    "        with autocast(enabled=use_amp):  # autocast ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        loss = loss / accumulation_steps  # ì†ì‹¤ ì •ê·œí™”\n",
    "\n",
    "        scaler.scale(loss).backward()  # ìŠ¤ì¼€ì¼ë§ëœ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            if use_amp:\n",
    "                scaler.step(optimizer)  # ìŠ¤ì¼€ì¼ë§ëœ ê·¸ë˜ë””ì–¸íŠ¸ë¡œ ì˜µí‹°ë§ˆì´ì € ì—…ë°ì´íŠ¸\n",
    "                scaler.update()  # ìŠ¤ì¼€ì¼ëŸ¬ ì—…ë°ì´íŠ¸\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item() * accumulation_steps\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.argmax(dim=1).detach().cpu().numpy())  # ì •ìˆ˜ ë ˆì´ë¸”ë¡œ ë³€í™˜\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    if val_loader:\n",
    "        val_preds, val_targets = [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device, dtype=torch.long)\n",
    "\n",
    "                if mixup_fn is not None:\n",
    "                    images, targets = mixup_fn(images, targets)\n",
    "\n",
    "                preds = model(images)\n",
    "                val_preds.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "                val_targets.extend(targets.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        val_loss = loss_fn(preds, targets).item()\n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        val_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "\n",
    "        ret.update({\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1\": val_f1,\n",
    "            \"val_preds\": val_preds,  # val_predsë¥¼ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€\n",
    "            \"val_targets\": val_targets,  # val_targetsë¥¼ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€\n",
    "        })\n",
    "        \n",
    "        if epoch is not None:\n",
    "                    epoch_interval = max(1, EPOCHS // 20)  # ì „ì²´ epochsì˜ 1/20 ê°„ê²©ìœ¼ë¡œ ë¡œê·¸ ì¶œë ¥\n",
    "                    if (epoch + 1) % epoch_interval == 0 or epoch == 0 or epoch == EPOCHS - 1:\n",
    "                        print(f\"Epoch: {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                            f\"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations import (\n",
    "    Compose, RandomResizedCrop, Resize, HorizontalFlip, VerticalFlip,\n",
    "    RandomRotate90, Rotate, GaussianBlur, HueSaturationValue,\n",
    "    RandomBrightnessContrast, Normalize\n",
    ")\n",
    "\n",
    "# ì¦ê°• ê¸°ë²• ì •ì˜\n",
    "def get_train_augmentation(img_size, mixup_prob=0.5, alpha=1.0):\n",
    "    augmentation = Compose([\n",
    "        RandomResizedCrop(height=img_size, width=img_size, scale=(0.8, 1.0), p=0.5),\n",
    "        Resize(height=img_size, width=img_size),\n",
    "        HorizontalFlip(p=0.6),\n",
    "        VerticalFlip(p=0.6),\n",
    "        RandomRotate90(p=0.5),\n",
    "        Rotate(limit=(-35, 35), p=0.5),\n",
    "        GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        \n",
    "        # í´ë˜ìŠ¤ ê°„ ì°¨ì´ ë¶€ê°ì„ ìœ„í•œ ì¶”ê°€ ê¸°ë²•\n",
    "        A.ImageCompression(quality_lower=60, quality_upper=100, p=0.5),  # ì´ë¯¸ì§€ ì••ì¶• ë° í’ˆì§ˆ ì €í•˜\n",
    "        A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.5), # CoarseDropout ì¶”ê°€\n",
    "        Normalize(mean=[0.57433558, 0.58330406, 0.58818927],\n",
    "                    std=[0.18964056, 0.18694252, 0.18506919]),\n",
    "                    #ì§ì ‘ êµ¬í•¨\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    # Wandbì— ì¦ê°• ê¸°ë²• ê¸°ë¡\n",
    "    wandb.config.update({\"augmentation\": str(augmentation)})\n",
    "    return augmentation\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ ê¸°ë²• ì •ì˜\n",
    "def get_test_augmentation(img_size):\n",
    "    return Compose([\n",
    "        Resize(height=img_size, width=img_size),\n",
    "        Normalize(mean=[0.57433558, 0.58330406, 0.58818927],\n",
    "                    std=[0.18964056, 0.18694252, 0.18506919]),\n",
    "                    #ì§ì ‘ êµ¬í•¨\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, num_augmentations=1):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.num_augmentations = num_augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) * self.num_augmentations\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_idx = idx // self.num_augmentations\n",
    "        image_path = self.image_paths[image_idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[image_idx]\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            if 'mixup' in augmented:\n",
    "                label = augmented['mixup']['target']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"ì¡°ê¸° ì¢…ë£Œ(Early stopping) ì„ ìœ„í•œ í´ë˜ìŠ¤\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_f1_max = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_f1, model):\n",
    "        score = val_f1\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_f1, model):\n",
    "        \"\"\"ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì €ì¥í•©ë‹ˆë‹¤\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f'Validation F1 score increased ({self.val_f1_max:.6f} --> {val_f1:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_f1_max = val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (self.alpha * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "        if self.reduction == 'none':\n",
    "            return focal_loss\n",
    "        elif self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "train_df = pd.read_csv(\"/data/ephemeral/home/data/train.csv\", usecols=['ID', 'target'])\n",
    "train_image_paths = [f\"/data/ephemeral/home/data/train/{fname}\" for fname in train_df['ID']]\n",
    "train_labels = train_df['target'].values\n",
    "\n",
    "test_df = pd.read_csv(\"/data/ephemeral/home/data/sample_submission.csv\")\n",
    "test_image_paths = test_df['ID'].apply(lambda x: f\"/data/ephemeral/home/data/test/{x}\").tolist()\n",
    "test_labels = [0] * len(test_image_paths)  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ëŠ” ë ˆì´ë¸”ì´ ì—†ìœ¼ë¯€ë¡œ ë”ë¯¸ ë ˆì´ë¸” ì‚¬ìš©\n",
    "\n",
    "tst_dataset = ImageDataset(test_image_paths, test_labels, transform=get_test_augmentation(img_size))\n",
    "tst_loader = DataLoader(tst_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:16<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Train Loss: 0.2346, Val Loss: 0.1185, Train Acc: 0.8455, Val Acc: 0.8736, Train F1: 0.8365, Val F1: 0.8507\n",
      "Validation F1 score increased (inf --> 0.850680).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0125: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:17<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score increased (0.850680 --> 0.877809).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:18<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score increased (0.877809 --> 0.898740).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2785: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:18<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0044: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:17<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100, Train Loss: 0.1074, Val Loss: 0.0146, Train Acc: 0.9305, Val Acc: 0.8854, Train F1: 0.9287, Val F1: 0.8784\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:18<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1973: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:17<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score increased (0.898740 --> 0.899823).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:18<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:17<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0022: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:18<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100, Train Loss: 0.0848, Val Loss: 0.1421, Train Acc: 0.9409, Val Acc: 0.9194, Train F1: 0.9402, Val F1: 0.9177\n",
      "Validation F1 score increased (0.899823 --> 0.917740).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:17<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:39<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [02:28<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [02:26<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: reducing learning rate of group 0 to 8.5850e-04.\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0367: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [02:28<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100, Train Loss: 0.0698, Val Loss: 1.5060, Train Acc: 0.9469, Val Acc: 0.9115, Train F1: 0.9468, Val F1: 0.9098\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:31<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [02:27<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Train Loss: 0.0657, Val Loss: 0.0006, Train Acc: 0.9505, Val Acc: 0.9726, Train F1: 0.9494, Val F1: 0.9710\n",
      "Validation F1 score increased (0.917740 --> 0.970975).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:34<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [02:29<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Train Loss: 0.0656, Val Loss: 0.0002, Train Acc: 0.9449, Val Acc: 0.9675, Train F1: 0.9443, Val F1: 0.9693\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:33<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [02:31<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Train Loss: 0.0597, Val Loss: 0.0000, Train Acc: 0.9505, Val Acc: 0.9758, Train F1: 0.9496, Val F1: 0.9756\n",
      "Validation F1 score increased (0.970975 --> 0.975580).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:31<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [02:33<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Train Loss: 0.0605, Val Loss: 0.0001, Train Acc: 0.9531, Val Acc: 0.9739, Train F1: 0.9522, Val F1: 0.9734\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:32<00:00,  6.03it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stratified K-Fold Cross Validation ì„¤ì •\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "wandb.config.update({\"n_splits\": str(n_splits)})\n",
    "\n",
    "\n",
    "fold_scores = []\n",
    "\n",
    "# 5ê°œì˜ Foldì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥ ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "pred_probs = []\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "\n",
    "loss_fn = FocalLoss(alpha = loss_alpha, gamma=loss_gamma)\n",
    "model.dropout = nn.Dropout(p=dropout_ratio)\n",
    "\n",
    "# AdamW ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR,weight_decay=0.03994)\n",
    "wandb.config.update({\"optimizer\": str(optimizer)})\n",
    "\n",
    "# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# ì¡°ê¸° ì¢…ë£Œ ì„¤ì •\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "# ê° foldì— ëŒ€í•´ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_image_paths, train_labels)):\n",
    "    print(f'Fold {fold+1}/{n_splits}')\n",
    "\n",
    "    # í•™ìŠµ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„° ë¶„ë¦¬\n",
    "    train_paths = [train_image_paths[i] for i in train_idx]\n",
    "    train_labels_ = [train_labels[i] for i in train_idx]\n",
    "    val_paths = [train_image_paths[i] for i in val_idx]\n",
    "    val_labels = [train_labels[i] for i in val_idx]\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
    "    train_dataset = ImageDataset(train_paths, train_labels_, transform=get_train_augmentation(img_size, mixup_prob=0.5, alpha=1.0), num_augmentations=num_augmentations)\n",
    "    val_dataset = ImageDataset(val_paths, val_labels, transform=get_train_augmentation(img_size, mixup_prob=0.5, alpha=1.0), num_augmentations=num_augmentations)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "    wandb.watch(model, log='all')\n",
    "\n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    for epoch in range(EPOCHS):\n",
    "        mixup_fn = Mixup(mixup_alpha=alpha, cutmix_alpha=0.0, \n",
    "                         prob=mixup_prob, switch_prob=0.0, mode='batch', label_smoothing=0.0, num_classes=17)\n",
    "        results = train_one_epoch(train_loader, model, optimizer, loss_fn, device, val_loader, epoch, mixup_fn)\n",
    "\n",
    "        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
    "        scheduler.step(results['val_f1'])\n",
    "        wandb.log({\"epoch\": epoch, \"train_loss\": results[\"train_loss\"], \"train_acc\": results[\"train_acc\"], \"train_f1\": results[\"train_f1\"],\n",
    "                   \"val_loss\": results[\"val_loss\"], \"val_acc\": results[\"val_acc\"], \"val_f1\": results[\"val_f1\"]})\n",
    "        \n",
    "        # ì¡°ê¸° ì¢…ë£Œ í™•ì¸\n",
    "        early_stopping(results['val_f1'], model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # ëª¨ë¸ í‰ê°€\n",
    "    val_preds = results['val_preds']\n",
    "    val_targets = results['val_targets']\n",
    "    val_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "    fold_scores.append(val_f1)\n",
    "    wandb.log({\"val_f1\": val_f1})\n",
    "\n",
    "    \n",
    "    # í˜„ì¬ Fold ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥  ì €ì¥\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        fold_pred_probs = []\n",
    "        for image, _ in tqdm(tst_loader):\n",
    "            image = image.to(device)\n",
    "            preds = model(image)\n",
    "            fold_pred_probs.extend(preds.softmax(dim=1).detach().cpu().numpy())\n",
    "        pred_probs.append(fold_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro F1 Score: 0.9598\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ í‰ê·  ì ìˆ˜ ê³„ì‚°\n",
    "mean_score = np.mean(fold_scores)\n",
    "print(f'Mean Macro F1 Score: {mean_score:.4f}')\n",
    "wandb.log({\"mean_score\": mean_score})\n",
    "\n",
    "pred_probs_mean = np.mean(pred_probs, axis=0)\n",
    "preds_list_argmax = np.argmax(pred_probs_mean, axis=1)\n",
    "wandb.log({\"pred_probs\": pred_probs})\n",
    "wandb.log({\"preds_list\": preds_list_argmax})\n",
    "\n",
    "submission_df = pd.read_csv(\"/data/ephemeral/home/data/sample_submission.csv\")\n",
    "submission_df['target'] = preds_list_argmax\n",
    "submission_df.to_csv(\"submission1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
